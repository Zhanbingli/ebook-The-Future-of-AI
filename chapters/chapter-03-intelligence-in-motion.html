
<!DOCTYPE HTML>
<html lang="en" >
    <head>
        <meta charset="UTF-8">
        <title>Chapter 3: Intelligence in Motion · The Future of AI: Insights from Industry Leaders</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 6.1.4">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="chapter-04-ai-revolutionizing-discovery.html" />
    
    
    <link rel="prev" href="chapter-02-the-science-of-scaling.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Title Page
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../foreword.html">
            
                <a href="../foreword.html">
            
                    
                    Foreword
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../table-of-contents.html">
            
                <a href="../table-of-contents.html">
            
                    
                    Table of Contents
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="chapter-01-the-art-of-scaling.html">
            
                <a href="chapter-01-the-art-of-scaling.html">
            
                    
                    Chapter 1: The Art of Scaling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="chapter-02-the-science-of-scaling.html">
            
                <a href="chapter-02-the-science-of-scaling.html">
            
                    
                    Chapter 2: The Science of Scaling
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.6" data-path="chapter-03-intelligence-in-motion.html">
            
                <a href="chapter-03-intelligence-in-motion.html">
            
                    
                    Chapter 3: Intelligence in Motion
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="chapter-04-ai-revolutionizing-discovery.html">
            
                <a href="chapter-04-ai-revolutionizing-discovery.html">
            
                    
                    Chapter 4: AI Revolutionizing Discovery
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="chapter-05-the-search-revolution.html">
            
                <a href="chapter-05-the-search-revolution.html">
            
                    
                    Chapter 5: The Search Revolution
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="chapter-06-building-faster.html">
            
                <a href="chapter-06-building-faster.html">
            
                    
                    Chapter 6: Building Faster
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="chapter-07-the-creative-imperative.html">
            
                <a href="chapter-07-the-creative-imperative.html">
            
                    
                    Chapter 7: The Creative Imperative
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="chapter-08-the-code-generation-revolution.html">
            
                <a href="chapter-08-the-code-generation-revolution.html">
            
                    
                    Chapter 8: The Code Generation Revolution
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="chapter-09-software-is-changing-again.html">
            
                <a href="chapter-09-software-is-changing-again.html">
            
                    
                    Chapter 9: Software is Changing (Again)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="chapter-10-digital-superintelligence-and-multiplanetary-life.html">
            
                <a href="chapter-10-digital-superintelligence-and-multiplanetary-life.html">
            
                    
                    Chapter 10: Digital Superintelligence and Multiplanetary Life
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="chapter-11-the-spatial-intelligence-revolution.html">
            
                <a href="chapter-11-the-spatial-intelligence-revolution.html">
            
                    
                    Chapter 11: The Spatial Intelligence Revolution
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="chapter-12-microsoft-s-ai-transformation.html">
            
                <a href="chapter-12-microsoft-s-ai-transformation.html">
            
                    
                    Chapter 12: Microsoft's AI Transformation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16" data-path="chapter-13-the-future-of-openai.html">
            
                <a href="chapter-13-the-future-of-openai.html">
            
                    
                    Chapter 13: The Future of OpenAI
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17" data-path="../epilogue-synthesizing-the-future.html">
            
                <a href="../epilogue-synthesizing-the-future.html">
            
                    
                    Epilogue: Synthesizing the Future
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18" data-path="../expanded-conclusion.html">
            
                <a href="../expanded-conclusion.html">
            
                    
                    Expanded Conclusion: The Convergence of Transformation
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Chapter 3: Intelligence in Motion</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="chapter-3-intelligence-in-motion">Chapter 3: Intelligence in Motion</h1>
<p><em>Chelsea Finn on Building General-Purpose Robots</em></p>
<h3 id="beyond-the-single-purpose-machine">Beyond the Single-Purpose Machine</h3>
<p>For decades, robotics has been trapped in a paradox: to solve any meaningful problem, you essentially need to build an entire company around that specific application. Want robots for logistics? Build specialized hardware, develop custom software, design unique movement primitives, and handle countless edge cases—all from scratch. The result has been a fragmented landscape where robotic solutions remain expensive, brittle, and limited in scope.</p>
<p>Chelsea Finn and her team at Physical Intelligence are pursuing a fundamentally different approach: developing general-purpose models that can enable any robot to perform any task in any environment. "We're trying to develop a general purpose model that can enable any robot to do any task in any environment," Finn explains. "We think that this sort of generalist model may work better and be easier to use than purpose-built models, just like we've seen in the development of foundation models for language."</p>
<h3 id="the-data-dilemma">The Data Dilemma</h3>
<p>The path to general-purpose robotics faces a crucial challenge that sets it apart from other AI domains: the nature of training data. While language models can train on vast corpora of human-generated text, robotics data comes with unique constraints and trade-offs.</p>
<p>Industrial automation provides massive scale—robots performing the same tasks millions of times. But this data lacks the diversity needed for general intelligence. "This sort of data isn't going to allow robots to go into disaster zones or to make a sandwich or to bag groceries," Finn notes.</p>
<p>YouTube videos offer behavioral diversity, showing humans performing countless different tasks. However, there's a fundamental embodiment gap: "We don't learn how to write by watching other people write, and we don't become expert tennis players by watching Wimbledon."</p>
<p>Simulation can generate unlimited synthetic data, but it struggles with realism and the sim-to-real transfer problem.</p>
<p>The solution, Finn discovered, requires high-quality real-world robot data, even if the quantities are smaller than what other AI domains enjoy. "Scale is necessary for developing these models that can generalize in open world conditions, but it's subordinate to actually solving the problem."</p>
<h3 id="the-laundry-folding-breakthrough">The Laundry Folding Breakthrough</h3>
<p>One of Physical Intelligence's most impressive demonstrations—a robot that can unload a dryer and fold laundry—illustrates both the potential and the challenges of general-purpose robotics. "To date, I think this is the most impressive thing that I've seen a robot do in the physical world," Finn says. "It's really hard."</p>
<p>The task requires handling variability in clothing types, positions, and crumpling patterns while maintaining dexterity over a 10-minute sequence with numerous opportunities for catastrophic failure. The breakthrough came through a counterintuitive insight borrowed from language model development: pre-training on all available data, then fine-tuning on a carefully curated, high-quality dataset.</p>
<p>"We pre-train on all the data and then fine-tune on a curated, consistent, high-quality set of demonstration data," Finn explains. This approach proved far superior to training only on curated data or only on the full dataset without fine-tuning.</p>
<h3 id="the-foundation-model-advantage">The Foundation Model Advantage</h3>
<p>The power of foundation models in robotics becomes clear when considering how quickly new capabilities can be developed. The same pre-training and post-training recipe that enabled laundry folding also worked for entirely different tasks: cleaning tables, scooping coffee beans, constructing cardboard boxes, and lighting candles with matches.</p>
<p>More remarkably, the approach transferred across different robots with minimal adaptation. "They collected data, sent the data to us, we fine-tuned our model on their data... the model is able to control the robot to make a cup of coffee," Finn describes, referring to a collaboration with a robot she had never seen in person.</p>
<p>This transferability hints at the true potential of foundation models in robotics: the ability to amortize learning across tasks, environments, and even physical platforms.</p>
<h3 id="scaling-across-environments">Scaling Across Environments</h3>
<p>Physical Intelligence's approach to environmental generalization demonstrates the power of diverse training data. They collected robot data in homes across San Francisco, in mock kitchens and bedrooms, totaling more than 100 unique rooms. Crucially, this mobile manipulation data represented only 2.4% of their overall pre-training mix, yet it enabled robots to operate successfully in entirely novel environments.</p>
<p>When tested in rented Airbnbs the robots had never visited, the systems successfully performed tasks like closing cabinets, putting away dishes, and cleaning spills. "Quantitatively, we find that if we actually increase the amount of homes, the amount of locations that are represented in the data, the performance increases," Finn reports.</p>
<h3 id="the-language-connection">The Language Connection</h3>
<p>One of the most sophisticated aspects of Physical Intelligence's approach involves hierarchical vision-language-action models. The system breaks down complex natural language instructions into subtasks, then executes them through low-level motor controls.</p>
<p>But training such systems faces a data bottleneck: it's impractical to collect massive amounts of human-robot interaction data for every possible command. The solution involves synthetic data generation, where language models create hypothetical human prompts for existing robot behaviors.</p>
<p>"We take data that says here's a video and then the next skill is to pick up a KitKat... we can ask a vision language model, what is a hypothetical prompt that a human might have asked that led to this particular scenario," Finn explains.</p>
<p>This approach enables robots to respond to open-ended prompts like "Can you make me a vegan sandwich? I don't like pickles, though," and handle real-time interjections like "Get me something sweet that's not in the basket."</p>
<h3 id="the-technical-architecture">The Technical Architecture</h3>
<p>Physical Intelligence's technical approach centers on vision-language-action (VLA) models that combine pre-trained vision-language models with action prediction heads. The key insight is preserving the language-following capabilities of the foundation model while adding robotic control capabilities.</p>
<p>"We're going to be predicting tokenized actions, and when we have the diffusion head, we'll be stopping the gradient from the randomly initialized diffusion head to prevent it from deteriorating the language following abilities of the VLM backbone," Finn explains.</p>
<p>This architectural choice proved crucial for maintaining the robot's ability to follow instructions accurately—achieving an 80% success rate compared to just 20% with approaches that didn't preserve the pre-trained knowledge.</p>
<h3 id="the-integration-challenge">The Integration Challenge</h3>
<p>One of the most underappreciated aspects of robotics development is the infrastructure required for real-time control. "We have a real-time system that needs to actually be hitting a certain frequency to actually execute actions successfully," Finn notes. "If you have lag in that system, it introduces all sorts of challenges."</p>
<p>This infrastructure layer—encompassing real-time control, multimodal data ingestion, and large-scale model training—represents a significant engineering challenge that goes well beyond the machine learning components that typically receive attention.</p>
<h3 id="lessons-from-failure">Lessons from Failure</h3>
<p>Physical Intelligence's development process included months of failure that provide valuable insights. When early approaches to laundry folding achieved 0% success rates despite trying various architectural improvements, the breakthrough came from stepping back and applying lessons from language model development.</p>
<p>"We had around two to three months of failure where nothing was really working," Finn admits. The eventual solution required not just better algorithms, but better training data curation and the discipline to maintain focus on a concrete, measurable task.</p>
<h3 id="the-path-forward">The Path Forward</h3>
<p>Finn's vision for the future of robotics centers on the continued development of foundation models that can generalize across tasks, environments, and platforms. However, she maintains a realistic perspective on current limitations and remaining challenges.</p>
<p>"There's lots of work to do still," she acknowledges, citing issues with speed, partial observability, and long-term planning. Success rates of around 80% for relatively simple tasks indicate significant room for improvement before robots can reliably handle complex real-world scenarios.</p>
<h3 id="implications-for-builders">Implications for Builders</h3>
<p>For entrepreneurs and technologists, Physical Intelligence's approach offers several key insights:</p>
<p><strong>Start with Real Data</strong>: Despite the appeal of simulation or large-scale industrial data, breakthrough capabilities require high-quality, diverse real-world training data.</p>
<p><strong>Embrace Foundation Models</strong>: The ability to pre-train once and fine-tune for multiple tasks provides significant advantages over building specialized systems from scratch.</p>
<p><strong>Focus on Concrete Tasks</strong>: Progress comes from tackling specific, measurable challenges rather than pursuing vague goals like "AI for robotics."</p>
<p><strong>Invest in Infrastructure</strong>: The unglamorous but crucial work of building reliable real-time systems often determines the difference between impressive demos and useful products.</p>
<h3 id="the-broader-vision">The Broader Vision</h3>
<p>Physical Intelligence's work represents more than just better robots—it points toward a future where intelligent systems can operate effectively in the physical world. This capability could transform manufacturing, healthcare, domestic life, and countless other domains where physical manipulation remains a bottleneck.</p>
<p>The company's approach of starting with concrete tasks while building toward general-purpose capability offers a template for navigating the transition from narrow AI applications to more broadly capable systems. As Finn puts it, "We've seen a few different scenarios in this talk where general purpose robots might be more successful than specialist robots because we can essentially, rather than start from scratch for every single application, actually build upon a much broader foundation for physical intelligence in the real world."</p>
<p>This foundation model approach to robotics may well prove to be as transformative for physical intelligence as large language models have been for digital intelligence, opening up possibilities that we're only beginning to imagine.</p>
<hr></hr>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="chapter-02-the-science-of-scaling.html" class="navigation navigation-prev " aria-label="Previous page: Chapter 2: The Science of Scaling">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="chapter-04-ai-revolutionizing-discovery.html" class="navigation navigation-next " aria-label="Next page: Chapter 4: AI Revolutionizing Discovery">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Chapter 3: Intelligence in Motion","level":"1.6","depth":1,"next":{"title":"Chapter 4: AI Revolutionizing Discovery","level":"1.7","depth":1,"path":"chapters/chapter-04-ai-revolutionizing-discovery.md","ref":"chapters/chapter-04-ai-revolutionizing-discovery.md","articles":[]},"previous":{"title":"Chapter 2: The Science of Scaling","level":"1.5","depth":1,"path":"chapters/chapter-02-the-science-of-scaling.md","ref":"chapters/chapter-02-the-science-of-scaling.md","articles":[]},"dir":"ltr"},"config":{"plugins":[],"root":"./docs","styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"The Future of AI: Insights from Industry Leaders","language":"en","gitbook":"3.2.3","description":"Talks and analyses from AI founders and researchers compiled into a GitBook."},"file":{"path":"chapters/chapter-03-intelligence-in-motion.md","mtime":"2025-09-20T03:12:10.790Z","type":"markdown"},"gitbook":{"version":"6.1.4","time":"2025-09-20T03:12:16.141Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/@honkit/honkit-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

