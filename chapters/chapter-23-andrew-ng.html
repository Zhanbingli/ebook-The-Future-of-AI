
<!DOCTYPE HTML>
<html lang="en" >
    <head>
        <meta charset="UTF-8">
        <title>Chapter 23: Andrew Ng: Building Faster with AI · The Future of AI: Insights from Industry Leaders</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 6.1.4">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="chapter-24-françois-chollet.html" />
    
    
    <link rel="prev" href="chapter-22-chelsea-finn.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Title Page
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../foreword.html">
            
                <a href="../foreword.html">
            
                    
                    Foreword
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../table-of-contents.html">
            
                <a href="../table-of-contents.html">
            
                    
                    Table of Contents
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="chapter-01-the-art-of-scaling.html">
            
                <a href="chapter-01-the-art-of-scaling.html">
            
                    
                    Chapter 1: The Art of Scaling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="chapter-02-the-science-of-scaling.html">
            
                <a href="chapter-02-the-science-of-scaling.html">
            
                    
                    Chapter 2: The Science of Scaling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="chapter-03-intelligence-in-motion.html">
            
                <a href="chapter-03-intelligence-in-motion.html">
            
                    
                    Chapter 3: Intelligence in Motion
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="chapter-04-ai-revolutionizing-discovery.html">
            
                <a href="chapter-04-ai-revolutionizing-discovery.html">
            
                    
                    Chapter 4: AI Revolutionizing Discovery
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="chapter-05-the-search-revolution.html">
            
                <a href="chapter-05-the-search-revolution.html">
            
                    
                    Chapter 5: The Search Revolution
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="chapter-06-building-faster.html">
            
                <a href="chapter-06-building-faster.html">
            
                    
                    Chapter 6: Building Faster
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="chapter-07-the-creative-imperative.html">
            
                <a href="chapter-07-the-creative-imperative.html">
            
                    
                    Chapter 7: The Creative Imperative
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="chapter-08-the-code-generation-revolution.html">
            
                <a href="chapter-08-the-code-generation-revolution.html">
            
                    
                    Chapter 8: The Code Generation Revolution
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="chapter-09-software-is-changing-again.html">
            
                <a href="chapter-09-software-is-changing-again.html">
            
                    
                    Chapter 9: Software is Changing (Again)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="chapter-10-digital-superintelligence-and-multiplanetary-life.html">
            
                <a href="chapter-10-digital-superintelligence-and-multiplanetary-life.html">
            
                    
                    Chapter 10: Digital Superintelligence and Multiplanetary Life
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="chapter-11-the-spatial-intelligence-revolution.html">
            
                <a href="chapter-11-the-spatial-intelligence-revolution.html">
            
                    
                    Chapter 11: The Spatial Intelligence Revolution
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15" data-path="chapter-12-microsoft-s-ai-transformation.html">
            
                <a href="chapter-12-microsoft-s-ai-transformation.html">
            
                    
                    Chapter 12: Microsoft's AI Transformation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.16" data-path="chapter-13-the-future-of-openai.html">
            
                <a href="chapter-13-the-future-of-openai.html">
            
                    
                    Chapter 13: The Future of OpenAI
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.17" data-path="chapter-14-synthesis-and-convergence.html">
            
                <a href="chapter-14-synthesis-and-convergence.html">
            
                    
                    Chapter 14: Synthesis and Convergence
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.18" data-path="chapter-15-why-startups-win-in-the-AI-era.html">
            
                <a href="chapter-15-why-startups-win-in-the-AI-era.html">
            
                    
                    Chapter 15: Why Startup Win in The AI era
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.19" data-path="chapter-16-Software-in-ai.html">
            
                <a href="chapter-16-Software-in-ai.html">
            
                    
                    Chapter 16: Andrej Karpathy: Software Is Changing (Again)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.20" data-path="chapter-17-digital-superintelligence.html">
            
                <a href="chapter-17-digital-superintelligence.html">
            
                    
                    Chapter 17: Elon Musk: Digital Superintelligence, Multiplanetary Life, How to Be Useful
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.21" data-path="chapter-18-dylan-field.html">
            
                <a href="chapter-18-dylan-field.html">
            
                    
                    Chapter 18: Dylan Field: Scaling Figma and the Future of Design
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.22" data-path="chapter-19-michael-truell.html">
            
                <a href="chapter-19-michael-truell.html">
            
                    
                    Chapter 19: Michael Truell: Building Cursor At 23, Taking On GitHub Copilot & Advice To Engineering Students
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.23" data-path="chapter-20-aravind-srinivas.html">
            
                <a href="chapter-20-aravind-srinivas.html">
            
                    
                    Chapter 20: Aravind Srinivas: Perplexity's Race to Build Agentic Search
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.24" data-path="chapter-21-jared-kaplan.html">
            
                <a href="chapter-21-jared-kaplan.html">
            
                    
                    Chapter 21: Anthropic Co-founder Jared Kaplan: Scaling and the Road to Human-Level AI
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.25" data-path="chapter-22-chelsea-finn.html">
            
                <a href="chapter-22-chelsea-finn.html">
            
                    
                    Chapter 22: Nobel Laureate John Jumper: AI is Revolutionizing Scientific Discovery
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.26" data-path="chapter-23-andrew-ng.html">
            
                <a href="chapter-23-andrew-ng.html">
            
                    
                    Chapter 23: Andrew Ng: Building Faster with AI
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.27" data-path="chapter-24-françois-chollet.html">
            
                <a href="chapter-24-françois-chollet.html">
            
                    
                    Chapter 24: François Chollet: How We Get To AGI
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.28" data-path="chapter-25-Fei-Fei-Li.html">
            
                <a href="chapter-25-Fei-Fei-Li.html">
            
                    
                    Chapter 25: Fei-Fei Li: Spatial Intelligence is the Next Frontier in AI
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.29" data-path="chapter-26-Sam-Altman.html">
            
                <a href="chapter-26-Sam-Altman.html">
            
                    
                    Chapter 26: Sam Altman on OpenAI's Journey: From AGI Dreams to the Future of Intelligence
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.30" data-path="chapter-27-Satya-Nadella.html">
            
                <a href="chapter-27-Satya-Nadella.html">
            
                    
                    Chapter 27: Microsoft's AI Strategy: Satya Nadella on Hyperscaling, Quantum Computing, and the Future of Work
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.31" data-path="chapter-28-chelsea-finn.html">
            
                <a href="chapter-28-chelsea-finn.html">
            
                    
                    Chapter 28:Chelsea Finn: Building Robots That Can Do Anything
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.32" data-path="../epilogue-synthesizing-the-future.html">
            
                <a href="../epilogue-synthesizing-the-future.html">
            
                    
                    Epilogue: Synthesizing the Future
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.33" data-path="../expanded-conclusion.html">
            
                <a href="../expanded-conclusion.html">
            
                    
                    Expanded Conclusion: The Convergence of Transformation
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Chapter 23: Andrew Ng: Building Faster with AI</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="building-ai-startups-faster-lessons-from-the-trenches">Building AI Startups Faster: Lessons from the Trenches</h1>
<p><strong>Date:</strong> July 10, 2025<br></br><strong>Source:</strong> <a href="https://www.youtube.com/watch?v=RNJCfif1dPY" target="_blank">YouTube Talk</a></p>
<p>It's great to see all of you here today. Since this is billed as Startup School, I want to share some lessons I've learned about building startups at AI Fund. AI Fund is a venture studio where we build an average of one startup per month. Because we co-found these startups, we're deeply involved—writing code, talking to customers, designing features, and determining pricing. We've completed many iterations of not just watching others build startups, but actually being in the trenches, building startups alongside entrepreneurs.</p>
<p>Today, I want to share the lessons I've learned from building startups, particularly around this rapidly changing AI technology and what it enables. My focus will be on the theme of speed. For those of you looking to build a startup, I believe a strong predictor of a startup's odds of success is execution speed. I have tremendous respect for entrepreneurs and executives who can execute quickly, and new AI technology is enabling startups to move much faster than ever before.</p>
<h2 id="the-ai-stack-and-where-opportunities-lie">The AI Stack and Where Opportunities Lie</h2>
<p>Before diving into speed, many people ask me: "Andrew, where are the opportunities for startups?" Here's how I think about the AI stack: at the lowest level are semiconductor companies, then cloud hyperscalers built on top of that, followed by AI foundation model companies. While much of the PR excitement and hype has focused on these technology layers, the biggest opportunities almost by definition must be at the application layer. We need applications to generate even more revenue so they can afford to pay the foundation, cloud, and semiconductor technology layers.</p>
<p>For whatever reason, media and social media don't talk about the application layer as much, but for those of you building startups, the biggest opportunities almost by definition have to be there—although opportunities certainly exist at all layers of the stack.</p>
<h2 id="the-rise-of-agentic-ai">The Rise of Agentic AI</h2>
<p>One thing that's changed dramatically over the past year is what I consider the most important tech trend in AI: the rise of agentic AI. About a year and a half ago, when I started giving talks to convince people that AI agents might be significant, I didn't realize that around last summer, marketers would get hold of this term and use it as a sticker to slap on everything in sight, which somewhat diluted its meaning. But let me share why, from a technical perspective, I think agentic AI is exciting, important, and opens up many more startup opportunities.</p>
<p>The way most of us use large language models (LLMs) is to prompt them to generate output. We ask the AI to produce something as if we were asking a human to write an essay from the first word to the last word in one go, without ever using backspace. Humans don't do their best writing when forced to type in this linear order, and neither does AI. Despite the difficulty of this linear constraint, our LLMs perform surprisingly well.</p>
<p>With agentic workflows, we can ask an AI system to first write an essay outline, then conduct web research if needed, fetch relevant web pages for context, write a first draft, read and critique that draft, revise it, and so on. This creates an iterative workflow where the model thinks, researches, revises, and returns to thinking, cycling through this loop multiple times. While slower, it delivers a much better work product.</p>
<p>For many projects AI Fund has worked on—from parsing complex compliance documents to medical diagnosis to reasoning about complex legal documents—we've found that agentic workflows make the crucial difference between something working versus not working. Much valuable business building still involves taking existing or new workflows and implementing them as agentic workflows.</p>
<p>To update the AI stack picture: over the past year, a new agentic orchestration layer has emerged that helps application builders orchestrate or coordinate numerous calls to the underlying technology layers. This orchestration layer has made building applications even easier, but I believe the basic conclusion that the application layer must be the most valuable layer of the stack still holds true.</p>
<h2 id="best-practices-for-startup-speed">Best Practices for Startup Speed</h2>
<h3 id="focus-on-concrete-ideas">Focus on Concrete Ideas</h3>
<p>At AI Fund, we focus exclusively on concrete ideas. A concrete product idea is one specified in enough detail that an engineer can build it. For example, "let's use AI to optimize healthcare assets" is not concrete—it's too vague. Different engineers would build completely different things, and because it's not concrete, you can't build it quickly.</p>
<p>In contrast, "let's write software to let hospitals allow patients to book MRI machine slots online to optimize usage" is concrete. I don't know if this is a good or bad idea, but it is concrete, meaning engineers can build it quickly. If it's a good idea, you'll discover that. If it's not, you'll discover that too. Having concrete ideas buys you speed.</p>
<p>The deceptive thing for many entrepreneurs is that vague ideas tend to receive kudos. If you tell friends "we should use AI to optimize healthcare assets," everyone will say it's a great idea. But it's not actually a great idea in the sense of being something you can build. When you're vague, you're almost always right, but when you're concrete, you may be right or wrong. Either outcome is fine—we can discover the truth much faster, which is crucial for startups.</p>
<h3 id="the-power-of-subject-matter-expertise">The Power of Subject Matter Expertise</h3>
<p>Finding good concrete ideas usually requires someone—perhaps you—who is a subject matter expert to think about a problem for a long time. Before starting Coursera, I spent years thinking about online education, talking to users, and developing intuitions about what would make a good edtech platform. After that long process—what YC sometimes calls "wandering the idea maze"—experts who have deeply considered a problem can make rapid decisions. When you ask such experts whether to build this feature or that feature, their gut instinct, which is instantaneous, can be a surprisingly good proxy for making quality decisions.</p>
<p>While I work in AI and you might think I'd emphasize data, getting data for many startups is actually a slow mechanism for making decisions. A subject matter expert with good instincts is often a much better mechanism for speedy decision-making.</p>
<h3 id="the-one-hypothesis-rule">The One Hypothesis Rule</h3>
<p>At any moment, many successful startups are pursuing one very clear hypothesis they're building out and trying to validate. Startups don't have resources to hedge and try ten things simultaneously. Pick one, pursue it doggedly, and if data tells you to lose faith in that idea, that's perfectly fine. Just pivot immediately to pursue a completely different concrete idea.</p>
<p>This often describes how AI Fund operates: we pursue one thing with determination until the world tells us we were wrong, then change and pursue a totally different thing with equal determination and doggedness.</p>
<p>If every piece of new data causes you to pivot, it probably means you're starting from too weak a knowledge base. If every customer conversation completely changes your mind, you likely don't know enough about that sector yet to have a high-quality concrete idea. Finding someone who has thought about a subject longer may put you on a better path to move faster.</p>
<h2 id="the-build-feedback-loop-revolution">The Build-Feedback Loop Revolution</h2>
<p>One of the biggest changes in how we build with AI involves rapidly evolving coding assistance and the build-feedback loop. When building applications, one of the biggest risks is customer acceptance—many startups struggle not because they can't build what they want, but because they build something nobody cares about.</p>
<p>For many application startups (less so for deep tech or technology startups), we build software (an engineering task), get feedback from users (a product management task), then based on user feedback, tweak our views on what to build and return to writing more software. We iterate around this loop many times toward product-market fit.</p>
<p>With AI coding assistance, rapid engineering is becoming possible in ways that simply weren't feasible before. Engineering speed is increasing rapidly while engineering costs are decreasing rapidly. This changes how we drive startups around this loop.</p>
<h3 id="the-two-types-of-software-development">The Two Types of Software Development</h3>
<p>I categorize the software I build into two major buckets:</p>
<ol>
<li><p><strong>Quick and dirty prototypes</strong> to test ideas—build a customer service chatbot, AI to process legal documents, whatever. Build a quick prototype to see if it works.</p>
</li>
<li><p><strong>Production software</strong>—maintaining production-ready codebases with all the complexity that entails.</p>
</li>
</ol>
<p>When writing production-quality code, depending on which analyst report you trust (it's hard to find rigorous data), we might be 30-50% faster with AI systems. But for building quick and dirty prototypes, we're not just 50% faster—I think we're easily 10 times faster, maybe much more.</p>
<p>Several factors contribute to this dramatic speed increase for prototypes: there's less integration with legacy software, infrastructure, and data needed. Requirements for reliability, scalability, and even security are much lower. I know I'm not supposed to tell people to write insecure code, but I routinely tell my team: "Go ahead, write insecure code." If the software only runs on your laptop and you don't plan to maliciously hack your own laptop, insecure code is fine. Of course, once it seems to be working, make it secure before shipping it to anyone else.</p>
<p>I find that startups are increasingly pursuing innovation by systematically building 20 prototypes to see what works. I know there's some anxiety in AI about many proofs of concept not making it to production, but by driving the cost of proof of concepts low enough, it's actually fine if many don't see the light of day.</p>
<h3 id="the-evolution-of-ai-coding-tools">The Evolution of AI Coding Tools</h3>
<p>The AI coding assistance landscape has evolved rapidly. Three or four years ago, we had code autocomplete popularized by GitHub Copilot. Then came Cursor and Windsurf—a generation of AI-enabled IDEs that are great. Starting six or seven months ago, we began seeing a new generation of highly agentic coding assistants. I use Claude Sonnet quite a lot for coding, and Claude Code is fantastic. Since the Claude 4 release, it's become my preference, though ask me again in a few months and I may be using something different. The tools are evolving rapidly.</p>
<p>This new generation of highly agentic coding assistance is making developer productivity continue to grow. Being even half a generation or one generation behind makes a big difference compared to staying on top of the latest tools. My team takes really different approaches to software engineering now compared to even three or six months ago.</p>
<h3 id="code-as-a-less-valuable-artifact">Code as a Less Valuable Artifact</h3>
<p>One surprising development: we're used to thinking of code as a valuable artifact because it was so hard to create. But because the cost of software engineering is plummeting, code is much less valuable than it used to be. I'm on teams where we've completely rebuilt a codebase three times in the past month because it's not that difficult anymore to rebuild a codebase or pick a new data schema.</p>
<p>You may have heard Jeff Bezos's terminology of "two-way doors" versus "one-way doors." A two-way door is a decision you can make and, if you change your mind, reverse relatively cheaply. A one-way door is a decision that's very costly or difficult to reverse. Choosing the software architecture of your tech stack used to be a one-way door. Once you built on a certain tech stack and set a database schema, it was really hard to change.</p>
<p>While I don't want to say it's totally a two-way door now, my team will more often build on a certain tech stack, then a week later, change our minds and throw the codebase away to redo it from scratch on a new tech stack. I don't want to overhype this—we don't do it all the time, and there are still costs to redoing work. But my team is rethinking what constitutes a one-way door versus what's now a two-way door because the cost of software engineering is much lower.</p>
<h2 id="empowering-everyone-to-build-with-ai">Empowering Everyone to Build with AI</h2>
<p>Going beyond software engineering, I believe this is a good time to empower everyone to build with AI. Over the past year, many people advised others not to learn to code on the grounds that AI would automate it away. I think we'll look back on this as some of the worst career advice ever given. As better tools make software engineering easier, more people should do it, not fewer.</p>
<p>When the world moved from punch cards to keyboards and terminals, it made coding easier. When we moved from assembly to high-level languages like COBOL, there were actually people arguing that now that we had COBOL, we didn't need programmers anymore. People actually wrote papers to that effect. Of course, that was wrong. Programming languages made it easier to code, and more people learned to code. Text editors, IDEs, AI coding assistants—as coding becomes easier, more people should learn to code.</p>
<p>I have a controversial opinion: I think it's time for everyone in every job role to learn to code. On my team, my CFO, head of talent, recruiters, and front desk person all know how to code. I see all of them performing better at their job functions because they can code. I'm probably a bit ahead of the curve—most businesses aren't there yet—but in the future, empowering everyone to code will make many people more productive.</p>
<h3 id="the-importance-of-commanding-computers">The Importance of Commanding Computers</h3>
<p>When I was teaching "Generative AI for Everyone" on Coursera, we needed to generate background art using Midjourney. One of my team members knew art history, so he could prompt Midjourney with specific genres, palettes, and artistic inspirations, giving him excellent control over generated images. We used all of his generated images. In contrast, I don't know art history, so when I prompted image generation, I could write "please make pretty pictures of robots for me," but I could never achieve the control my collaborator could.</p>
<p>With computers, one of the most important skills of the future is the ability to tell a computer exactly what you want so it will do it for you. People with deeper understanding of computers will be able to command computers to achieve desired outcomes. Learning to code—not necessarily writing code yourself, but steering AI to code for you—seems like it will remain the best way to do that for a long time.</p>
<h2 id="the-product-management-bottleneck">The Product Management Bottleneck</h2>
<p>With software engineering becoming much faster, I'm seeing interesting dynamics where product management work—getting user feedback and deciding what features to build—is increasingly becoming the bottleneck. Many of my teams have started complaining that they're bottlenecked on product engineering and design because the engineers have gotten so much faster.</p>
<p>Three to five years ago, Silicon Valley had somewhat suspicious but nonetheless typical rules of thumb: one product manager to four engineers, or one PM to seven engineers. These were standard PM-to-engineer ratios. With engineers becoming much faster while product management work isn't becoming faster at the same pace, I'm seeing this ratio shift.</p>
<p>Just yesterday, for the first time when planning headcount for a project, a team proposed not one PM to four engineers, but one PM to 0.5 engineers—essentially twice as many PMs as engineers. I still don't know if this is a good idea, but it's a sign of where the world is heading. I find that PMs who can code or engineers with product instincts often perform better.</p>
<h2 id="tactics-for-rapid-product-feedback">Tactics for Rapid Product Feedback</h2>
<p>Because engineering is accelerating, having good tactics for getting rapid feedback to shape your perspective on what to build faster helps you move faster overall. Here's a portfolio of tactics for getting product feedback, ranging from faster but less accurate to slower but more accurate:</p>
<ol>
<li><p><strong>Look at the product yourself and trust your gut</strong> (fastest) - If you're a subject matter expert, this is surprisingly effective.</p>
</li>
<li><p><strong>Ask three friends or teammates for feedback</strong> - Get them to play with your product and provide input.</p>
</li>
<li><p><strong>Ask three to ten strangers for feedback</strong> - One of the most important skills I've learned is how to sit in coffee shops or hotel lobbies (places with high foot traffic) and respectfully ask strangers for feedback on what I'm building. This used to be easier when I was less known. I've made numerous product decisions in hotel lobbies or coffee shops with collaborators.</p>
</li>
<li><p><strong>Send prototypes to 100 testers</strong> - If you have access to a logical group of users.</p>
</li>
<li><p><strong>A/B testing</strong> - Contrary to what many people think, A/B testing is now one of the slowest tactics in my menu because it's just slow to ship and depends on how many users you have.</p>
</li>
</ol>
<p>The missing piece many teams overlook: when I A/B test something, I don't just use the results to pick product A or product B. My team sits down and carefully examines the data to hone our instincts and improve our ability to use the first tactic (gut decisions) to make high-quality decisions faster. We think: "I thought this product name would work better than that product name. Clearly, my mental model of users is wrong." We sit down to update our mental model using all that data to improve the quality of our instincts for making product decisions faster.</p>
<h2 id="understanding-ai-provides-competitive-advantage">Understanding AI Provides Competitive Advantage</h2>
<p>I've seen that understanding AI actually makes you move faster, and here's why. With mature technologies like mobile, many people have had smartphones for a long time. We generally know what mobile apps can do, so many people, including non-technical people, have good instincts about mobile app capabilities.</p>
<p>Similarly, mature job roles like sales, marketing, HR, and legal are all important and difficult, but there are enough experienced practitioners whose knowledge is relatively diffused because these fields haven't changed dramatically in recent months.</p>
<p>But AI is an emerging technology, so knowledge of how to do AI really well is not widespread. Teams that truly understand AI have an advantage over teams that don't. While you can find someone who knows how to solve HR problems well, if you have an AI problem, knowing how to actually solve it could put you ahead of other companies.</p>
<p>Questions like "What accuracy can you get for a customer service chatbot?" "Should you use prompting, fine-tuning, or agentic workflows?" "How do you get voice AI to low latency?"—there are many decisions where making the right technical choice lets you solve problems in a couple of days, while making the wrong technical choice could lead you to chase blind alleys for three months.</p>
<p>I've been surprised that while one bit of information theoretically should at most make you twice as fast, in practice, if you flip the wrong bit, you're not twice as slow—you spend 10 times longer chasing blind alleys. This is why having the right technical judgment really makes startups move so much faster.</p>
<h2 id="the-building-blocks-of-ai">The Building Blocks of AI</h2>
<p>Another reason I find staying on top of AI helpful for startups: over the past two years, we've had numerous wonderful generative AI tools and building blocks. This partial list includes prompting workflows, evals, guardrails, RAG (Retrieval-Augmented Generation), voice AI, async programming, ETL, embeddings, fine-tuning, graph databases, and model integration. There's a long and wonderful list of building blocks that can be quickly combined to build software that no one on the planet could have built even a year ago.</p>
<p>This creates many new opportunities for startups to build new things. When I learned about these building blocks, I have a mental picture: if you own one building block—say you have a basic white building block and know how to prompt—you can build some amazing stuff with that one block. But if you acquire a second building block, like knowing how to build chatbots, you now have white and black Lego bricks and can build something more interesting.</p>
<p>Add a blue building block, and you can build something even more interesting. Get a few red building blocks, maybe a yellow one—more interesting. Get more building blocks, and very rapidly the number of things you can combine them into grows combinatorially or exponentially. Knowing all these wonderful building blocks lets you combine them in much richer combinations.</p>
<p>Deep Learning.AI works with leading AI companies worldwide to catalog and teach these building blocks. When I look at the Deep Learning.AI course catalog, whenever I take these courses to learn these building blocks, I feel like I'm acquiring new components that can combine to form combinatorially or exponentially more software applications that were impossible just one or two years ago.</p>
<h2 id="conclusion-speed-as-a-success-predictor">Conclusion: Speed as a Success Predictor</h2>
<p>There are many things that matter for startups, not just speed. But when I examine the startups AI Fund is building, I find that the management team's ability to execute at speed is highly correlated with odds of success.</p>
<p>Here's what we've learned to achieve speed:</p>
<ul>
<li><strong>Work on concrete ideas</strong> - They must be good concrete ideas, of course.</li>
<li><strong>Execute fast with good judgment</strong> - As an executive, I'm judged on both the speed and quality of my decisions. Both matter, but speed absolutely matters.</li>
<li><strong>Leverage rapid engineering with AI coding assistance</strong> - This makes you go much faster but shifts the bottleneck to getting user feedback on product decisions.</li>
<li><strong>Maintain a portfolio of tactics for rapid feedback</strong> - If you haven't learned to respectfully approach strangers in coffee shops for feedback, it's not easy, but it's a valuable skill for entrepreneurs.</li>
<li><strong>Stay on top of the technology</strong> - This knowledge buys you speed.</li>
</ul>
<p>The future belongs to those who can make computers do exactly what they want them to do. People who know how to use AI will be much more powerful than people who don't.</p>
<h2 id="qa-session">Q&amp;A Session</h2>
<p><strong>Question: As AI advances, do you think it's more important for humans to develop the tools or learn how to use the tools better? How can we position ourselves to remain essential in a world where intelligence is becoming democratized?</strong></p>
<p>I feel like AGI has been overhyped, so for a long time there will be many things that humans can do that AI cannot. In the future, the people who are most powerful are those who can make computers do exactly what they want them to do. I think staying on top of the tools—some of us will build tools sometimes, but there are many other tools others will build that we can just use—so people who know how to use AI to get computers to do what you want will be much more powerful. I don't worry about people running out of things to do, but people who can use AI will be much more powerful than people who don't.</p>
<p><strong>Question: What do you think about the future of compute? We see people saying let's ship GPUs to space, some talking about nuclear power data centers. What are your thoughts?</strong></p>
<p>There's a framework you can use for deciding what's hype and what's not. Over the last two years, a handful of companies have hyped up certain things for promotional, PR, and fundraising purposes. Because AI was so new, these companies got away with saying almost anything without fact-checking because the technology wasn't well understood.</p>
<p>One of my mental filters is that certain hype narratives make these businesses look more powerful and get amplified. For example, "AI is so powerful we might accidentally lead to human extinction"—that's just ridiculous, but it's a hype narrative that made certain businesses look more powerful and helped their fundraising goals. "AI is so powerful soon no one will have a job anymore"—just not true, but again, it made businesses look more powerful. "We are so powerful that by training a new model we will casually wipe out thousands of startups"—also not true. Yes, Jasper ran into trouble, and a small number of companies got wiped out, but it's not easy to casually wipe out thousands of startups.</p>
<p>"AI needs so much electricity, only nuclear power is good enough—wind and solar just won't cut it"—that's just not true. GPUs in space? Go for it, but I think we have a lot of room to run still for terrestrial GPUs. Some of these hype narratives have been amplified and are distortions of what will actually be done.</p>
<p><strong>Question: What are some of the most dangerous biases or overhyped narratives that you've seen people get poisoned by that we should try to avoid to have a more realistic view as we build this future?</strong></p>
<p>The dangerous AI narrative has been overhyped. AI is a fantastic tool, but like any powerful tool like electricity, there are many ways to use it beneficially and some ways to use it harmfully. I don't use the term "AI safety" much—not because I think we should build dangerous things, but because safety isn't a function of technology; it's a function of how we apply it.</p>
<p>An electric motor manufacturer can't guarantee that no one will use it for unsafe downstream tasks. Electric motors can be used to build useful machines or harmful ones, but the manufacturer can't control downstream usage. Safety isn't a function of the electric motor; it's a function of how you apply it. The same goes for AI—it's neither safe nor unsafe. How we use it responsibly or irresponsibly determines whether what we build ends up being harmful or beneficial.</p>
<p>Instead of thinking about AI safety, I often think about responsible AI. Sometimes really weird corner cases get hyped in the news. Just a day or two ago, there was a Wall Street Journal article about losing control of AI that took corner case lab experiments and sensationalized them disproportionately. Unfortunately, technology is hard enough to understand that many people don't know better, so these hype narratives keep getting amplified. This has been used as a weapon against open source software, which is really unfortunate.</p>
<p><strong>Question: How should aspiring founders think about business in a world where anything can be disrupted in a day? Whatever great moat, product, or feature you have can be replicated with AI and code, and competitors can emerge in hours.</strong></p>
<p>When you start a business, there are many things to worry about, but the number one thing I worry about is: are you building a product that users love? There are lots of considerations—go-to-market channels, competitors, technology, moats—all important, but if I had singular focus, it would be on building a product that users really want. Until you solve that, it's very difficult to build a valuable business.</p>
<p>After you solve that, other questions come into play: Do you have a channel to reach customers? What's your pricing long-term? What's your moat? I find that moats tend to be overhyped. More businesses start with a product and then evolve into a moat. Consumer products and brands are somewhat more defensible. If you have momentum, it becomes harder to catch you. Enterprise products sometimes have moats if there are hard-to-access channels.</p>
<p>At AI Fund, we do fairly complex analysis of these factors, writing two-to-six-page narrative memos before deciding whether to proceed. All these things are important, but right now, the number of opportunities—the amount of stuff possible that no one's built yet—seems much greater than the number of people with skills to build them. At the application layer, there's a lot of white space for new things no one else is working on. Focus on building a product that people want and love, then figure out the rest along the way.</p>
<p><strong>Question: You mentioned that current AI tools are like bricks that can be built upon through accumulation. However, it's difficult to see accumulative functional expansion because they often rely on stacking functions based on intent distribution, accompanied by dynamic problems of tokens and time overhead, which differs from static engineering. What's your perspective on possible agent accumulation effects in the future?</strong></p>
<p>My most common advice to developers is: to first approximation, just don't worry about token costs. Only a small number of startups are lucky enough to have users use their product so much that token costs become a problem. I've been on teams where user adoption made our generative AI bills climb in concerning ways, but it's difficult to get to that point where token usage costs are a problem.</p>
<p>For teams lucky enough that users made token costs a problem, we often had engineering solutions to bend the curve back down through prompting optimization, fine-tuning, or other techniques.</p>
<p>I'm seeing agentic workflows that integrate many different steps. For example, a customer service chatbot often uses prompting, maybe optimizes results, builds evals and guardrails, and might need RAG to get information to feedback to users. I do see these things grow.</p>
<p>One tip: I architect software to make switching between different building block providers relatively easy. We have products built on top of language models, but sometimes if you ask which model we're using, I honestly don't know because we built evals, and when new models are released, we quickly run evals to see if they're better. We'll switch to new models if evals show they work better. Our engineers sometimes change models without telling me because evals show new models work better.</p>
<p>Switching costs for foundation models are relatively low, and we architect software to preserve flexibility. Switching costs for orchestration platforms are harder, but maintaining flexibility in building block choices lets you go faster even as you build more complex systems.</p>
<p><strong>Question: In education and AI, there are two paradigms: AI can make teachers more productive by automating grading and homework, versus personal tutors for every student. How do you see these paradigms converging, and what will education look like in the next five years?</strong></p>
<p>Everyone feels change coming in edtech, but I don't think the disruption is here yet. Many teams are experimenting. Coursera has Coursera Coach, which works well. DeepLearning.AI focuses on teaching AI and has built-in chatbots. There's an avatar of me on the DeepLearning.AI website you can talk to. Many teams experiment with autograding.</p>
<p>For language learning, companies like Speak and Duolingo have shown clearer ways AI transforms the experience. For the broader educational landscape, I see tons of experimentation, but the final end state isn't clear. I think education will be hyperpersonalized, but whether that's through avatars, text chatbots, or other workflows isn't yet determined.</p>
<p>The hype from a couple years ago that AGI would make everything easy was just hype. Reality is that work is complex. Teachers and students do really complex workflows, and for the next decade, we'll be mapping existing work to agentic workflows. Education is one sector where this mapping is still underway but not mature enough for the end state to be clear.</p>
<p><strong>Question: AI has great potential for good but also potential for bad consequences like exacerbating economic inequality. How should AI builders balance product building with potential societal downsides? How can we move fast and be responsible?</strong></p>
<p>Look in your heart—if fundamentally what you're building won't make people at large better off, don't do it. I know it sounds simple, but it's actually hard to do in the moment. At AI Fund, we've killed multiple projects not on financial grounds but on ethical grounds. There were projects where the economic case was solid, but we said we don't want this to exist in the world and killed it.</p>
<p>I hope more people will do that. I also worry about bringing everyone with us. People in job roles that aren't engineering are much more productive if they know AI than if they don't. On my marketing team, marketers who know how to code run circles around those who don't. So everyone learned to code and got better. Trying to bring everyone with us and ensure everyone is empowered to build with AI will be an important part of what we all do.</p>
<p><strong>Question: There seems to be a growing gap between what AI can actually do and what people perceive it can do. Is it important to educate the general public about deep learning, not just technical people?</strong></p>
<p>That knowledge will diffuse. DeepLearning.AI wants to empower everyone to build with AI, so we're working on it, along with many others.</p>
<p>There are maybe two dangers. One is if we don't bring people with us fast enough—I hope we'll solve that. There's another danger: if you look at the mobile ecosystem, it's not that interesting because there are two gatekeepers—Android and iOS. Unless they let you do certain things, you can't try them on mobile, which hampers innovators.</p>
<p>The dangers of AI have been used by certain businesses trying to shut down open source because some businesses would love to be gatekeepers to large-scale foundation models. Hyping up false dangers of AI to get regulators to pass laws like the proposed SB 1047 in California—which thank goodness we shut down—would have put burdensome regulatory requirements that don't make anyone safer but would make it difficult for teams to release open source and open weight software.</p>
<p>One danger to inequality is if these regulatory approaches succeed, leaving us with a small number of gatekeepers where everyone needs permission from a few companies to fine-tune models or prompt in certain ways. That would stifle innovation and prevent diffusion of information that lets lots of startups build responsibly but with freedom to innovate.</p>
<p>So long as we prevent this line of attack on open source models from succeeding—we've made good progress, but the threat is still there—I think eventually we'll get knowledge diffusion and hopefully bring everyone with us. But the fight to protect open source is ongoing.</p>
<p><strong>Question: How should we think about business in a world where moats can be replicated quickly with AI and code?</strong></p>
<p>When you start a business, there are many things to worry about, but the number one thing is: are you building a product that users love? Until you solve that, it's very difficult to build a valuable business. After you solve that, other questions matter—channels, pricing, moats—but I find moats tend to be overhyped.</p>
<p>More businesses start with a product and evolve into a moat. Consumer products and brands are somewhat more defensible. If you have momentum, it's harder to catch you. For enterprise products, moats might exist if there are hard-to-access channels.</p>
<p>At this moment, the number of opportunities—things possible that no one's built yet—seems much greater than the number of people with skills to build them. At the application layer, there's lots of white space. Focus on building a product people want and love, then figure out the rest along the way.</p>
<hr></hr>
<p><em>This article is based on Andrew Ng's talk at Startup School, covering lessons learned from building AI startups at AI Fund, with particular focus on execution speed and practical tactics for leveraging AI technology in startup development.</em></p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="chapter-22-chelsea-finn.html" class="navigation navigation-prev " aria-label="Previous page: Chapter 22: Nobel Laureate John Jumper: AI is Revolutionizing Scientific Discovery">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="chapter-24-françois-chollet.html" class="navigation navigation-next " aria-label="Next page: Chapter 24: François Chollet: How We Get To AGI">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Chapter 23: Andrew Ng: Building Faster with AI","level":"1.26","depth":1,"next":{"title":"Chapter 24: François Chollet: How We Get To AGI","level":"1.27","depth":1,"path":"chapters/chapter-24-françois-chollet.md","ref":"chapters/chapter-24-françois-chollet.md","articles":[]},"previous":{"title":"Chapter 22: Nobel Laureate John Jumper: AI is Revolutionizing Scientific Discovery","level":"1.25","depth":1,"path":"chapters/chapter-22-chelsea-finn.md","ref":"chapters/chapter-22-chelsea-finn.md","articles":[]},"dir":"ltr"},"config":{"plugins":[],"root":"./docs","styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"The Future of AI: Insights from Industry Leaders","language":"en","gitbook":"3.2.3","description":"Talks and analyses from AI founders and researchers compiled into a GitBook."},"file":{"path":"chapters/chapter-23-andrew-ng.md","mtime":"2025-09-30T07:34:44.025Z","type":"markdown"},"gitbook":{"version":"6.1.4","time":"2025-09-30T07:34:55.907Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/@honkit/honkit-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

